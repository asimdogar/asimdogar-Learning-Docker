Get Started, Part 3: Services
https://docs.docker.com/get-started/part3/

Compose is a tool for defining and running multi-container Docker applications. With Compose, you use a YAML file to configure your application’s services. Then, with a single command, you create and start all the services from your configuration. 

 we scale our application and enable load-balancing. To do this, we must go one level up in the hierarchy of a distributed application: the service.


    Stack
    Services (you are here)
    Container (covered in part 2)

Services are really just “containers in production.” A service only runs one image, but it codifies the way that image runs—what ports it should use, how many replicas of the container should run so the service has the capacity it needs, and so on. Scaling a service changes the number of container instances running that piece of software, assigning more computing resources to the service in the process


First Intstall Docker compose
https://docs.docker.com/compose/overview/


Your first docker-compose.yml file

A docker-compose.yml file is a YAML file that defines how Docker containers should behave in production.
docker-compose.yml
-------------------------------------------------
version: "3"
services:
  web:
    # replace username/repo:tag with your name and image details
    image: username/repo:tag
    deploy:
      replicas: 5
      resources:
        limits:
          cpus: "0.1"
          memory: 50M
      restart_policy:
        condition: on-failure
    ports:
      - "4000:80"
    networks:
      - webnet
networks:
  webnet:
--------------------------------------------------
This docker-compose.yml file tells Docker to do the following:

    Pull the image we uploaded in step 2 from the registry.

    Run 5 instances of that image as a service called web, limiting each one to use, at most, 10% of a single core of CPU time (this could also be e.g. “1.5” to mean 1 and half core for each), and 50MB of RAM.

    Immediately restart containers if one fails.

    Map port 4000 on the host to web’s port 80.

    Instruct web’s containers to share port 80 via a load-balanced network called webnet. (Internally, the containers themselves publish to web’s port 80 at an ephemeral port.)

    Define the webnet network with the default settings (which is a load-balanced overlay network).

Run your new load-balanced app

Before we can use the docker stack deploy command we first run:

$ docker swarm init

    Note: We get into the meaning of that command in part 4. If you don’t run docker swarm init you get an error that “this node is not a swarm manager.”

Now let’s run it. You need to give your app a name. Here, it is set to getstartnssedlab:

docker stack deploy -c docker-compose.yml getstartedlab

Our single service stack is running 5 container instances of our deployed image on one host. Let’s investigate.

Get the service ID for the one service in our application:

$ docker service ls

docker stack services getstartedlab
ID                  NAME                MODE                REPLICAS            IMAGE               PORTS
bqpve1djnk0x        getstartedlab_web   replicated          5/5                 username/repo:tag   *:4000->80/tcp

A single container running in a service is called a task. Tasks are given unique IDs that numerically increment, up to the number of replicas you defined in docker-compose.yml. List the tasks for your service:

docker service ps getstartedlab_web

Tasks also show up if you just list all the containers on your system, though that is not filtered by service:

docker container ls -q

You can run curl -4 http://localhost:4000 several times in a row, or go to that URL in your browser and hit refresh a few times..

$ docker stack ps getstartedlab





